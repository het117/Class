{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c0878d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63012383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchsummary import summary\n",
    "from tqdm import tqdm\n",
    "import datetime\n",
    "from collections import namedtuple\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74606342",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0'if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c504121",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_directory = r'./data/cat/'\n",
    "dog_directory = r'./data/dog/'\n",
    "\n",
    "cat_images_filepaths = glob(cat_directory + '*.jpg')\n",
    "dog_images_filepaths = glob(dog_directory + '*.jpg')\n",
    "\n",
    "images_filepaths = [*cat_images_filepaths[:3000], *dog_images_filepaths[:3000]]\n",
    "random.seed(42)\n",
    "random.shuffle(images_filepaths)\n",
    "\n",
    "train_path, test_path = train_test_split(images_filepaths, test_size=0.2, random_state=42)\n",
    "train_path, val_path, = train_test_split(train_path, test_size=0.25, random_state=42)\n",
    "print(len(train_path), len(val_path), len(test_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4816b5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Custom_Dataset(Dataset):\n",
    "    def __init__(self, path, transforms=None):\n",
    "        self.path = path\n",
    "        self.transform = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.path)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.path[idx]\n",
    "        img = Image.open(img_path)\n",
    "        img = img.resize((224, 224))\n",
    "        \n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        \n",
    "        label = self.path[idx].split('\\\\')[-1].split('.')[0]\n",
    "        \n",
    "        if label == 'dog':\n",
    "            label = 1\n",
    "        elif label == 'cat':\n",
    "            label = 0\n",
    "        \n",
    "        return img, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd27c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7d4e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_set = Custom_Dataset(train_path, transforms=transform)\n",
    "val_set = Custom_Dataset(val_path, transforms=transform)\n",
    "test_set = Custom_Dataset(test_path, transforms=transform)\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
    "classes = ('cat', 'dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed803446",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지를 보여주기 위한 함수\n",
    "def imshow(img, label):\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(label)\n",
    "    plt.show()\n",
    "# 학습용 이미지를 무작위로 가져오기\n",
    "dataiter = next(iter(train_loader))\n",
    "images, labels = dataiter\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images), labels)\n",
    "# 정답(label) 출력\n",
    "print(' '.join(f'{classes[labels[j]]:5s}'for j in range(batch_size)))\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(4096, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(512, 2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "model = AlexNet().to(device)\n",
    "summary(model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff7ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_data_len = len(train_set)\n",
    "v_data_len = len(val_set)\n",
    "t_t_loss, t_t_acc = [], []\n",
    "t_v_loss, t_v_acc = [], []\n",
    "best_loss = np.inf\n",
    "\n",
    "for e in range(epoch):\n",
    "    r_t_loss, r_t_acc = 0.0, 0.0\n",
    "    r_v_loss, r_v_acc = 0.0, 0.0\n",
    "    \n",
    "    model.train()\n",
    "    for inputs, labels in tqdm(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        \n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        r_t_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        r_t_acc += torch.sum(pred == labels).item()\n",
    "    \n",
    "    t_t_loss.append(r_t_loss / t_data_len)\n",
    "    t_t_acc.append(r_t_acc / t_data_len)\n",
    "    \n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for inputs, labels in tqdm(val_loader):\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            r_v_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            _, pred = torch.max(outputs, 1)\n",
    "            r_v_acc += torch.sum(pred == labels).item()\n",
    "    \n",
    "    loss = r_v_loss / v_data_len\n",
    "    \n",
    "    t_v_loss.append(loss)\n",
    "    t_v_acc.append(r_v_acc / v_data_len)\n",
    "    \n",
    "    if best_loss > loss:\n",
    "        best_loss = loss\n",
    "        torch.save(model.state_dict(), './save_net.pth')\n",
    "    \n",
    "    print(\n",
    "        f'epoch : {e + 1}\\n'\n",
    "        f'train_loss : {t_t_loss[e]:.4f}\\ttrain_acc : {t_t_acc[e] * 100:.2f}%\\n'\n",
    "        f'val_loss : {t_v_loss[e]:.4f}\\tval_acc : {t_v_acc[e] * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a33adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(range(1, epoch + 1), t_t_loss, 'b', label='train_loss')\n",
    "plt.plot(range(1, epoch + 1), t_v_loss, 'r', label='val_loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend()\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, epoch + 1), t_t_acc, 'b', label='train_acc')\n",
    "plt.plot(range(1, epoch + 1), t_v_acc, 'r', label='val_acc')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('acc')\n",
    "plt.legend()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3df577",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./save_net.pth'))\n",
    "\n",
    "r_t_loss, r_t_acc = 0.0, 0.0\n",
    "t_data_len = len(test_set)\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for inputs, labels in tqdm(test_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        r_t_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        _, pred = torch.max(outputs, 1)\n",
    "        r_t_acc += torch.sum(pred == labels).item()\n",
    "loss = r_t_loss / t_data_len\n",
    "acc = r_t_acc / t_data_len\n",
    "print(f'Loss : {loss:.4f}, Accuracy : {acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23354671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트용 이미지를 무작위로 가져오기\n",
    "dataiter = next(iter(test_loader))\n",
    "images, labels = dataiter\n",
    "images = images.to(device)\n",
    "output = model(images)\n",
    "_, pred = torch.max(output, 1)\n",
    "# 이미지 보여주기\n",
    "imshow(torchvision.utils.make_grid(images.detach().cpu()), pred)\n",
    "# 예측, 정답(label) 출력\n",
    "print('예측 : ', end=\"\")\n",
    "print(' '.join(f'{classes[pred[j]]:5s}'for j in range(batch_size)))\n",
    "print('정답 : ', end=\"\")\n",
    "print(' '.join(f'{classes[labels[j]]:5s}'for j in range(batch_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f031292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGGNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204e0eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()        \n",
    "        self.features = features        \n",
    "        self.maxpool = nn.MaxPool2d(7)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(4096, output_dim),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f1905",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11_config = [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "vgg13_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M']\n",
    "vgg16_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, \n",
    "                512, 'M']\n",
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "                512, 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6afeba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):    \n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    \n",
    "    for c in config:\n",
    "        assert c == 'M'or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size = 2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c), nn.ReLU(inplace = True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace = True)]\n",
    "            in_channels = c\n",
    "            \n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bdaf364",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg11_layers = get_vgg_layers(vgg11_config, batch_norm = True)\n",
    "OUTPUT_DIM = 2\n",
    "model = VGG(vgg11_layers, OUTPUT_DIM).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a831fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b2ad0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):    \n",
    "    expansion = 1\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()                \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 3, \n",
    "                               stride = stride, padding = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, \n",
    "                               stride = 1, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None        \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):       \n",
    "        i = x       \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "                        \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c374fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bottleneck(nn.Module):    \n",
    "    expansion = 4\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride = 1, downsample = False):\n",
    "        super().__init__()    \n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = 1, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size = 3, stride = stride, padding = 1, bias = False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)        \n",
    "        self.conv3 = nn.Conv2d(out_channels, self.expansion * out_channels, kernel_size = 1,\n",
    "                               stride = 1, bias = False)\n",
    "        self.bn3 = nn.BatchNorm2d(self.expansion * out_channels)        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        \n",
    "        if downsample:\n",
    "            conv = nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size = 1, \n",
    "                             stride = stride, bias = False)\n",
    "            bn = nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            downsample = nn.Sequential(conv, bn)\n",
    "        else:\n",
    "            downsample = None            \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        i = x        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)        \n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)        \n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "                \n",
    "        if self.downsample is not None:\n",
    "            i = self.downsample(i)\n",
    "            \n",
    "        x += i\n",
    "        x = self.relu(x)\n",
    "    \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ceee7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, config, output_dim, zero_init_residual=False):\n",
    "        super().__init__()\n",
    "                \n",
    "        block, n_blocks, channels = config\n",
    "        self.in_channels = channels[0]            \n",
    "        assert len(n_blocks) == len(channels) == 4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size = 7, stride = 2, padding = 3, bias = False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size = 3, stride = 2, padding = 1)\n",
    "        \n",
    "        self.layer1 = self.get_resnet_layer(block, n_blocks[0], channels[0])\n",
    "        self.layer2 = self.get_resnet_layer(block, n_blocks[1], channels[1], stride = 2)\n",
    "        self.layer3 = self.get_resnet_layer(block, n_blocks[2], channels[2], stride = 2)\n",
    "        self.layer4 = self.get_resnet_layer(block, n_blocks[3], channels[3], stride = 2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(self.in_channels, output_dim)\n",
    "        if zero_init_residual:\n",
    "            for m in self.modules():\n",
    "                if isinstance(m, Bottleneck):\n",
    "                    nn.init.constant_(m.bn3.weight, 0)\n",
    "                elif isinstance(m, BasicBlock):\n",
    "                    nn.init.constant_(m.bn2.weight, 0)\n",
    "        \n",
    "    def get_resnet_layer(self, block, n_blocks, channels, stride = 1):   \n",
    "        layers = []        \n",
    "        if self.in_channels != block.expansion * channels:\n",
    "            downsample = True\n",
    "        else:\n",
    "            downsample = False\n",
    "        \n",
    "        layers.append(block(self.in_channels, channels, stride, downsample))\n",
    "        \n",
    "        for i in range(1, n_blocks):\n",
    "            layers.append(block(block.expansion * channels, channels))\n",
    "        self.in_channels = block.expansion * channels            \n",
    "        return nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec2eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "ResNetConfig = namedtuple('ResNetConfig', ['block', 'n_blocks', 'channels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b43411",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [2,2,2,2],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "resnet34_config = ResNetConfig(block = BasicBlock,\n",
    "                               n_blocks = [3,4,6,3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "resnet50_config = ResNetConfig(block = Bottleneck,\n",
    "                               n_blocks = [3, 4, 6, 3],\n",
    "                               channels = [64, 128, 256, 512])\n",
    "resnet101_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 4, 23, 3],\n",
    "                                channels = [64, 128, 256, 512])\n",
    "resnet152_config = ResNetConfig(block = Bottleneck,\n",
    "                                n_blocks = [3, 8, 36, 3],\n",
    "                                channels = [64, 128, 256, 512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47624aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIM = 2\n",
    "model = ResNet(resnet50_config, OUTPUT_DIM).to(device)\n",
    "print(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "het",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "vscode": {
   "interpreter": {
    "hash": "a54e74bf99199c62ede2494f3563958cb8e322912a43717fc858ebaf84d1e028"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
